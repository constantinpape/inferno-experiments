# Specify how the data needs to be sliced before feeding to the network.
# We use a 3D sliding window over the dataset to extract patches, which
# are then fed to the network as batches.
slicing_config:
  # Sliding window size
  window_size: [1, 1088, 1088]
  # Sliding window stride
  stride: [1, 1088, 1088]
  # Reflect padding on the loaded volume. Follows numpy.pad semantics.
  padding: [[0, 0], [32, 32], [32, 32]]
  # Data slice to iterate over.
  data_slice: ':, :, :'
    

# Specify paths to volumes
volume_config:
  # Raw data TODO correct path
  raw:
    path: '/g/kreshuk/data/isbi2012_challenge/vnc_train_volume.h5'
    # path: '/net/hciserver03/storage/cpape/Work/data/isbi_2012_challenge/isbi2012_train_volume.h5'
    # path: '/home/constantin/Work/neurodata_hdd/isbi12_data/isbi2012_train_volume.h5'
    path_in_h5_dataset: 'volumes/raw'
    dtype: 'float32'


# config for inference engine
gpu: 0
crop_padding: True
num_workers: 4
